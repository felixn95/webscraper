{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:25:06.263602Z",
     "start_time": "2024-06-17T15:25:04.018057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from DataProcessor import DataProcessor\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# read in combined stock data\n",
    "preprocessor = DataProcessor()\n",
    "# create df to current date\n",
    "df = preprocessor.process_nrw_data(\"06_17\")\n",
    "# remove bike sale since it is not relevant\n",
    "df = preprocessor.remove_fahrrad_sale(df)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Group by id, store_skuId, and store_storeId to find the number of stores per product variant\n",
    "product_store_counts = df.groupby(['id', 'store_skuId'])['store_storeId'].nunique().reset_index()\n",
    "product_store_counts = product_store_counts[product_store_counts['store_storeId'] >= 5]\n",
    "\n",
    "# Filter the main dataframe to include only those product variants\n",
    "df_filtered = df.merge(product_store_counts[['id', 'store_skuId']], on=['id', 'store_skuId'])\n",
    "\n",
    "# Find stock out events\n",
    "df_filtered['is_stock_out'] = (df_filtered['store_quantity'] == 0) & (df_filtered['store_quantity'].shift() > 0)\n",
    "\n",
    "# Identify product variants with at least 2 stock out events in different stores\n",
    "stock_out_events = df_filtered.groupby(['id', 'store_skuId', 'store_storeId'])['is_stock_out'].max().reset_index()\n",
    "stock_out_counts = stock_out_events.groupby(['id', 'store_skuId'])['is_stock_out'].sum().reset_index()\n",
    "stock_out_counts = stock_out_counts[stock_out_counts['is_stock_out'] >= 2]\n",
    "\n",
    "# filter the dataframe to include only those variants\n",
    "df_relevant_variants  = df_filtered.merge(stock_out_counts[['id', 'store_skuId']], on=['id', 'store_skuId'])\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: processed_nrw_data/06_17_nrw_stock_data.csv. Loading DataFrame from file.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:25:18.059062Z",
     "start_time": "2024-06-17T15:25:10.866267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from DataProcessor import DataProcessor\n",
    "\n",
    "# Assuming df_relevant_variants is your filtered dataframe\n",
    "df_relevant_variants['timestamp'] = pd.to_datetime(df_relevant_variants['timestamp'])\n",
    "df_relevant_variants.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Ensure that categorical columns are treated correctly\n",
    "categorical_columns = ['id', 'store_skuId', 'store_storeId', 'main_category', 'sub_category', 'product_name', 'brand', 'store_storeName']\n",
    "for col in categorical_columns:\n",
    "    df_relevant_variants[col] = df_relevant_variants[col].astype('category')\n",
    "\n",
    "# Group by id, store_skuId, and store_storeId and resample daily\n",
    "grouped = df_relevant_variants.groupby(['id', 'store_skuId', 'store_storeId'])\n",
    "\n",
    "# Resample to daily data and forward fill the quantity\n",
    "df_daily = grouped['store_quantity'].resample('D').ffill().reset_index()\n",
    "\n",
    "# Create lag features\n",
    "for lag in range(1, 22):\n",
    "    df_daily[f'quantity_lag_{lag}'] = df_daily.groupby(['id', 'store_skuId', 'store_storeId'])['store_quantity'].shift(lag)\n",
    "\n",
    "# Find stock out events for other stores\n",
    "df_daily['stock_out'] = (df_daily['store_quantity'] == 0)\n",
    "\n",
    "# Create a column to count stock outs in other stores\n",
    "df_daily['stock_out_other_stores'] = df_daily.groupby(['id', 'store_skuId', 'timestamp'])['stock_out'].transform('sum') - df_daily['stock_out']\n",
    "\n",
    "# Create lag features for stock outs in other stores\n",
    "for lag in range(1, 22):\n",
    "    df_daily[f'stock_out_other_stores_lag_{lag}'] = df_daily.groupby(['id', 'store_skuId', 'store_storeId'])['stock_out_other_stores'].shift(lag)\n",
    "\n",
    "# Get the latest timestamp for each product variant and store\n",
    "latest_timestamp = df_daily.groupby(['id', 'store_skuId', 'store_storeId'])['timestamp'].max().reset_index()\n",
    "\n",
    "# Merge to get the latest quantities and features\n",
    "df_final = df_daily.merge(latest_timestamp, on=['id', 'store_skuId', 'store_storeId', 'timestamp'], suffixes=('', '_latest'))\n",
    "\n",
    "# Select the relevant columns from the original dataframe to merge with df_final\n",
    "additional_columns = ['id', 'store_skuId', 'store_storeId', 'main_category', 'sub_category', 'product_name', 'brand', 'price', 'store_storeName']\n",
    "df_relevant_variants_reset = df_relevant_variants.reset_index()\n",
    "df_additional_info = df_relevant_variants_reset[additional_columns].drop_duplicates()\n",
    "\n",
    "# Merge additional information to df_final\n",
    "df_final = df_final.merge(df_additional_info, on=['id', 'store_skuId', 'store_storeId'])\n",
    "\n",
    "# Select the final relevant columns\n",
    "selected_columns = [\n",
    "    'id', 'main_category', 'sub_category', 'product_name', 'brand', 'price', \n",
    "    'store_skuId', 'store_storeId', 'store_storeName', 'timestamp', 'store_quantity'\n",
    "]\n",
    "selected_columns += [f'quantity_lag_{i}' for i in range(1, 22)]\n",
    "selected_columns += [f'stock_out_other_stores_lag_{i}' for i in range(1, 22)]\n",
    "\n",
    "df_final = df_final[selected_columns]\n",
    "df_final.rename(columns={'store_quantity': 'quantityLatest', 'timestamp': 'latestTimestamp'}, inplace=True)\n",
    "\n",
    "# Optionally, you can also add the earliest timestamp\n",
    "# Ensure that timestamp is not a categorical type before performing min operation\n",
    "df_relevant_variants_reset['timestamp'] = pd.to_datetime(df_relevant_variants_reset['timestamp'])\n",
    "earliest_timestamp = df_relevant_variants_reset.groupby(['id', 'store_skuId', 'store_storeId'])['timestamp'].min().reset_index()\n",
    "df_final = df_final.merge(earliest_timestamp, on=['id', 'store_skuId', 'store_storeId'], suffixes=('', '_earliest'))\n",
    "df_final.rename(columns={'timestamp': 'earliestTimestamp'}, inplace=True)\n",
    "\n",
    "\n",
    "# Display the prepared dataframe\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"Prepared DataFrame\", dataframe=df_final)\n"
   ],
   "id": "d79612fbbf87aea7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:27:01.305295Z",
     "start_time": "2024-06-17T15:27:01.116849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save to csv\n",
    "df_final.to_csv('processed_variant_development_per_store.csv', index=False)"
   ],
   "id": "8670fcc3864e02b4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "320e019e48102b17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
